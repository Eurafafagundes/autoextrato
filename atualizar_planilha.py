import os
import re
import fitz  # PyMuPDF para ler PDFs
import gspread
import pandas as pd
from datetime import datetime
from google.oauth2.service_account import Credentials
import joblib  # Para carregar o modelo treinado

# ===== CONFIGURA√á√ÉO =====
CAMINHO_CREDENCIAIS = "aqui poem o endere√ßo .json"
ID_PLANILHA = "aqui poem id da planilha google"
PASTA_EXTRATOS = "extratos"
ARQUIVO_PROCESSADOS = "processados.txt"  # Arquivo para armazenar PDFs j√° cadastrados
MODELO_ML = "modelo_categorizacao.pkl"  # Arquivo do modelo treinado

# ===== CARREGAR O MODELO DE MACHINE LEARNING =====
try:
    modelo = joblib.load(MODELO_ML)  # Carrega o modelo treinado
    vectorizer = joblib.load("vectorizer.pkl")  # Carrega o vetorizador corretamente
    print("‚úÖ Modelo e Vetorizador carregados com sucesso!")
except Exception as e:
    print(f"‚ùå Erro ao carregar o modelo: {e}")
    exit()

# ===== AUTENTICA√á√ÉO NO GOOGLE SHEETS =====
scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
credenciais = Credentials.from_service_account_file(CAMINHO_CREDENCIAIS, scopes=scopes)
cliente = gspread.authorize(credenciais)
planilha = cliente.open_by_key(ID_PLANILHA)
aba = planilha.sheet1  # Primeira aba da planilha

# ===== FUN√á√ÉO PARA GERENCIAR PDFs J√Å PROCESSADOS =====
def carregar_pdfs_processados():
    if os.path.exists(ARQUIVO_PROCESSADOS):
        with open(ARQUIVO_PROCESSADOS, "r") as f:
            return set(f.read().splitlines())  # Retorna um conjunto de PDFs j√° processados
    return set()

def salvar_pdf_processado(nome_arquivo):
    with open(ARQUIVO_PROCESSADOS, "a") as f:
        f.write(nome_arquivo + "\n")  # Adiciona o nome do PDF ao hist√≥rico

# ===== FUN√á√ÉO PARA LIMPAR O TEXTO =====
def limpar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r"[^\w\s]", "", texto)  # Remove pontua√ß√£o
    palavras_irrelevantes = ["pix", "compra", "pagamento", "cart√£o", "fatura", "transa√ß√£o"]
    palavras = texto.split()
    palavras_filtradas = [palavra for palavra in palavras if palavra not in palavras_irrelevantes]
    return " ".join(palavras_filtradas)

# ===== FUN√á√ÉO PARA CLASSIFICAR AUTOMATICAMENTE USANDO MACHINE LEARNING =====
def categorizar_transacao(descricao):
    if not isinstance(descricao, str):  # Garante que a entrada seja uma string
        descricao = str(descricao)

    descricao_limpa = limpar_texto(descricao)  # Limpa o texto antes de classificar

    print(f"üîç Vetorizando a descri√ß√£o -> {descricao_limpa}")  # Debug para testar

    # Transforma a descri√ß√£o em vetor
    try:
        descricao_transformada = vectorizer.transform([descricao_limpa])
        print(f"‚úÖ Vetor gerado com sucesso -> {descricao_transformada.shape}")  # Debug
    except ValueError:
        print(f"‚ö†Ô∏è Erro: A descri√ß√£o '{descricao_limpa}' cont√©m palavras desconhecidas pelo modelo.")
        return "Outros"  # Se houver erro, retorna "Outros"

    # Converter csr_matrix para array antes da previs√£o
    descricao_transformada_array = descricao_transformada.toarray()

    # Faz a previs√£o da categoria corretamente
    try:
        categoria_prevista = modelo.predict(descricao_transformada_array)[0]
        print(f"‚úÖ Previs√£o feita: {categoria_prevista}")  # Debug
    except Exception as e:
        print(f"‚ùå Erro ao prever categoria: {e}")
        return "Erro na previs√£o"

    return categoria_prevista  # Retorna a categoria prevista pelo modelo

# ===== FUN√á√ÉO PARA LER O CONTE√öDO DO PDF =====
def extrair_transacoes_pdf(caminho_pdf):
    doc = fitz.open(caminho_pdf)
    transacoes = []
    linhas_extracao = []

    for pagina in doc:
        texto = pagina.get_text("text")
        linhas = texto.split("\n")
        linhas_extracao.extend(linhas)

    for i in range(len(linhas_extracao) - 2):
        linha = linhas_extracao[i]
        ultima_linha = linhas_extracao[i + 2]  

        partes = linha.split()
        
        if len(partes) >= 2 and re.match(r"\d{2}/\d{2}/\d{4}", partes[0]):  
            data = partes[0]  
            descricao = " ".join(partes[1:]).lower()

            valor_str = ultima_linha.strip()
            valor_str = valor_str.replace(".", "").replace(",", ".")

            if not re.match(r"-?\d+\.\d+", valor_str):
                continue  

            valor = abs(float(valor_str))  

            # ===== CLASSIFICA√á√ÉO AUTOM√ÅTICA COM MACHINE LEARNING =====
            categoria = categorizar_transacao(descricao)

            transacoes.append([data, descricao.title(), categoria, valor])

    return transacoes

# ===== FUN√á√ÉO PARA ATUALIZAR A PLANILHA =====
def atualizar_planilha(novas_transacoes):
    if not novas_transacoes:
        print("Nenhuma nova transa√ß√£o para adicionar.")
        return

    novas_transacoes.sort(key=lambda x: datetime.strptime(x[0], "%d/%m/%Y"))

    aba.append_rows(novas_transacoes)
    print(f"{len(novas_transacoes)} novas transa√ß√µes adicionadas!")

# ===== EXECU√á√ÉO =====
def processar_pdfs():
    if not os.path.exists(PASTA_EXTRATOS):
        os.makedirs(PASTA_EXTRATOS)

    arquivos_pdfs = [f for f in os.listdir(PASTA_EXTRATOS) if f.endswith(".pdf")]

    if not arquivos_pdfs:
        print("Nenhum PDF encontrado na pasta.")
        return

    pdfs_processados = carregar_pdfs_processados()  # Carrega lista de PDFs j√° processados
    transacoes_existentes = set(tuple(linha[:3]) for linha in aba.get_all_values()[1:])
    novas_transacoes = []

    for arquivo in arquivos_pdfs:
        if arquivo in pdfs_processados:
            print(f"üìå {arquivo} j√° foi processado, pulando...")
            continue  # Pula o arquivo se j√° foi processado

        caminho_pdf = os.path.join(PASTA_EXTRATOS, arquivo)
        transacoes = extrair_transacoes_pdf(caminho_pdf)

        for transacao in transacoes:
            if tuple(map(str, transacao)) not in transacoes_existentes:
                novas_transacoes.append(transacao)

        salvar_pdf_processado(arquivo)  # Salva o PDF como processado ap√≥s adicionar os dados

    atualizar_planilha(novas_transacoes)

# ===== CHAMANDO O PROCESSO =====
if __name__ == "__main__":
    processar_pdfs()
